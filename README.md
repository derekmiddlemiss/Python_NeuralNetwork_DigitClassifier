# Python_NeuralNetwork_DigitClassifier
Implementation of a single hidden layer neural network from scratch in Python to classify small bitmaps of digits. 
Uses stochastic minibatch gradient descent to train. Compare this with normal batch gradient descent to see difference in efficiency.

To-do - (i) implement variable learning rate, possibly using momentum concept, AdaGrad; (ii) extend to treat multiple hidden layers
